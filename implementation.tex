\section{Implementation}
\label{sec:implementation}
In this section, we briefly discuss the implementation of key components of MBFQ in Windows
Server 2016.

{\bf Binary location}: MBFQ is implemented in Windows as a Hyper-V Virtual Switch Extension, 
which is an NDIS lightweight filter (LWF) driver.

Like other Windows LWF drivers, MBFQ uses a standard NDIS API to receive outgoing packets
from the upper stack, schedule them with its internal microschedulers and macroscheduler, and 
sends conformed packets to the lower stack through another standard NDIS API.
Thus, MBFQ implementation is completely abstracted from the application above, and the 
hardware below.  The only information from hardware that MBFQ receives is a standard NDIS API 
for receiving link state status to determine the link capacity of the underlying network adapter.

{\bf The macroscheduler}: MBFQ uses a timer to invoke the macroscheduler every 100 milliseconds.
If outgoing traffic to the network adapter does not exceed 80\% of the link capacity, the
macroscheduler deactivates the microschedulers (if they have not already been deactivated), and
immediately returns.  Thus, when the network adapter is not near its link capacity, which is the case
for most of the time in data centers, outgoing traffic is not throttled, and MBFQ uses minimal CPU.

If the network adapter is near its link capacity, the macroscheduler computes and distributes the
transmit rates to the microschedulers according to the pseudocode shown in  
Figure~\ref{fig:mbfq_p1} and Figure~\ref{fig:mbfq_p2}.

{\bf The microscheduler}: The microschedulers are implemented as token buckets, whose rates are
periodically adjusted by the macroscheduler. Because the microschedulers operate independently from
the macroscheduler on a per-packet basis, it is fairly straightforward to enable each microscheduler to 
schedule packets across multiple processors, using per-processor sub-queues that share a common 
token bucket. This provides a fully distributed fair bandwidth queuing implementation where packets can remain
on the same processor from the application layer all the way to the hardware transmit buffer.


